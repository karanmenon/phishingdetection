{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"malicious_phish.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.garage-pirenne.be/index.php?option=...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://adventure-nicaragua.net/index.php?optio...</td>\n",
       "      <td>defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url        type\n",
       "0                                   br-icloud.com.br    phishing\n",
       "1                mp3raid.com/music/krizz_kaliko.html      benign\n",
       "2                    bopsecrets.org/rexroth/cr/1.htm      benign\n",
       "3  http://www.garage-pirenne.be/index.php?option=...  defacement\n",
       "4  http://adventure-nicaragua.net/index.php?optio...  defacement"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LE = LabelEncoder()\n",
    "#df['label'] = LE.fit_transform(df['type'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features based on URL\n",
    "df[\"url length\"] = df[\"url\"].str.len()\n",
    "\n",
    "pathlength = []\n",
    "entropy = []\n",
    "hostlength = []\n",
    "isportinstring = []\n",
    "numofdigits = []\n",
    "numofparams = []\n",
    "numoffrags = []\n",
    "isencoded = []\n",
    "numencodedchar = []\n",
    "numsubdir = []\n",
    "numperiods = []\n",
    "clientinstring = []\n",
    "admininstring = []\n",
    "serverinstring = []\n",
    "logininstring = []\n",
    "tld =[]\n",
    "\n",
    "#Extract various features from URL\n",
    "for url in df[\"url\"].tolist():\n",
    "    pathlength.append(len(urlparse(url).path))\n",
    "    text = url.lower()\n",
    "    probs = [text.count(c) / len(text) for c in set(text)]\n",
    "    entropy.append( -sum([p * log(p) / log(2.0) for p in probs]))\n",
    "    hostlength.append(len(urlparse(url).netloc))\n",
    "    withport = urlparse(url).netloc.split(':')\n",
    "    isportinstring.append(len(withport) > 1 and withport[-1].isdigit())\n",
    "    numofdigits.append(len([i for i in url if i.isdigit()]))\n",
    "    numofparams.append(0 if urlparse(url).query == '' else len(urlparse(url).query.split('&')))\n",
    "    numoffrags.append(len(urlparse(url).fragment.split('#')) - 1 if urlparse(url).fragment == '' else 0)\n",
    "    isencoded.append('%' in url.lower())\n",
    "    numencodedchar.append(len([i for i in url if i == '%']))\n",
    "    numsubdir.append(len(urlparse(url).path.split('/')))\n",
    "    numperiods.append(len([i for i in url if i == '.']))\n",
    "    clientinstring.append('client' in url.lower())\n",
    "    admininstring.append('admin' in url.lower())\n",
    "    serverinstring.append('server' in url.lower())\n",
    "    logininstring.append('login' in url.lower())\n",
    "    tld.append(urlparse(url).netloc.split('.')[-1].split(':')[0])\n",
    "\n",
    "df[\"path length\"] = pathlength\n",
    "df[\"entropy\"] = entropy\n",
    "df[\"host length\"] = hostlength\n",
    "df[\"is port in string\"] = isportinstring\n",
    "df[\"number of digits\"] = numofdigits\n",
    "df[\"number of params\"] = numofparams\n",
    "df[\"number of fragments\"] = numoffrags\n",
    "df[\"is encoded\"] = isencoded\n",
    "df[\"num_encoded_char\"] = numencodedchar\n",
    "df[\"number of subdirectories\"] = numsubdir\n",
    "df[\"number of periods\"] = numperiods\n",
    "df[\"is client in string\"] = clientinstring\n",
    "df[\"is admin in string\"] = admininstring\n",
    "df[\"is server in string\"] = serverinstring\n",
    "df[\"is login in string\"] = logininstring\n",
    "df[\"tld\"] = tld\n",
    "\n",
    "LE = LabelEncoder()\n",
    "df['tld2'] = LE.fit_transform(df['tld'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "y = df[\"type\"]\n",
    "X = df.drop(labels=['url', 'type', 'tld'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "\n",
    "# will avoid K-nearest neighbors as it is not good on large datasets\n",
    "\n",
    "# will avoid decision tree as it is also not good on large datasets\n",
    "\n",
    "#Naive Bayes\n",
    "NBclassifier = GaussianNB()\n",
    "NBmodel = NBclassifier.fit(X_train, y_train)\n",
    "y_pred = NBmodel.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"F1: \",f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision: \",precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(n_estimators = 100)  \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"F1: \",f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision: \",precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost\n",
    "LE = LabelEncoder()\n",
    "df['types'] = LE.fit_transform(df['type'])\n",
    "\n",
    "y = df[\"types\"]\n",
    "X = df.drop(labels=['url', 'type', 'tld', 'types'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "boost = xgb.XGBClassifier()\n",
    "boost.fit(X_train, y_train)\n",
    "y_pred = boost.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"F1: \",f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Precision: \",precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall: \",recall_score(y_test, y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
